{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Inference Pipeline using Data Wrangler Flow & Autopilot Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pipeline import PipelineModel\n",
    "from sagemaker.model import Model\n",
    "from datetime import datetime\n",
    "import sagemaker\n",
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "s3_client = boto3.client('s3')\n",
    "timestamp = datetime.strftime(datetime.now(), '%Y-%m-%d-%H-%M-%S')\n",
    "iam_role = sagemaker.get_execution_role()\n",
    "inference_bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Push dataflow tar to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_flow_name = \"loans_2022-12-22-04-37-36.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Wrangler inference flow model URI: s3://sagemaker-us-east-1-119174016168/data_wrangler_inference_flows/loans_2022-12-22-04-37-36.tar.gz\n"
     ]
    }
   ],
   "source": [
    "s3_client.upload_file(inference_flow_name, inference_bucket, f\"data_wrangler_inference_flows/{inference_flow_name}\", ExtraArgs={\"ServerSideEncryption\": \"aws:kms\"})\n",
    "inference_flow_uri = f\"s3://{inference_bucket}/data_wrangler_inference_flows/{inference_flow_name}\"\n",
    "print(f\"Data Wrangler inference flow model URI: {inference_flow_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Get trained model location and image URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model URI: s3://sagemaker-us-east-1-119174016168/zbu92oclw48b-AutoMLS-Px6ThX1MiP/sagemaker-automl-candidates/model/WeightedEnsemble-L3-FULL-t3/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "automl_job_name = \"zbu92oclw48b-AutoMLS-Px6ThX1MiP\"\n",
    "automl_job_desc = session.describe_auto_ml_job(automl_job_name)\n",
    "best_inference_container = automl_job_desc[\"BestCandidate\"][\"InferenceContainers\"][0]\n",
    "algo_model_uri = best_inference_container[\"ModelDataUrl\"]\n",
    "print(f\"Model URI: {algo_model_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Image': '763104351884.dkr.ecr.us-east-1.amazonaws.com/autogluon-inference:0.4.3-cpu-py38-ubuntu20.04',\n",
       " 'ModelDataUrl': 's3://sagemaker-us-east-1-119174016168/zbu92oclw48b-AutoMLS-Px6ThX1MiP/sagemaker-automl-candidates/model/WeightedEnsemble-L3-FULL-t3/model.tar.gz',\n",
       " 'Environment': {'MODEL_NAME': 'WeightedEnsemble-L3-FULL',\n",
       "  'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT': 'text/csv',\n",
       "  'SAGEMAKER_INFERENCE_OUTPUT': 'predicted_label',\n",
       "  'SAGEMAKER_INFERENCE_SUPPORTED': 'predicted_label,probability,probabilities,labels',\n",
       "  'SAGEMAKER_PROGRAM': 'tabular_serve.py',\n",
       "  'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code'}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_inference_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dw_container_uri = \"663277389841.dkr.ecr.us-east-1.amazonaws.com/sagemaker-data-wrangler-container:1.x\"\n",
    "algo_container_uri = best_inference_container[\"Image\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create constituent models for the Inference Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_models = []\n",
    "target_column_name = 'loan_status'\n",
    "data_wrangler_model_name = f\"DataWranglerInferencePipelineFlowModel-{timestamp}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-create Data Wrangler model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wrangler_model = Model(image_uri=dw_container_uri, \n",
    "                            model_data=inference_flow_uri, \n",
    "                            role=iam_role, \n",
    "                            name=data_wrangler_model_name, \n",
    "                            sagemaker_session=session, \n",
    "                            env={\"INFERENCE_TARGET_COLUMN_NAME\": target_column_name})\n",
    "pipeline_models.append(data_wrangler_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-create trained model (here Autopilot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_model_name = f\"DataWranglerInferencePipelineAlgoModel-{timestamp}\"\n",
    "algo_environment = best_inference_container[\"Environment\"]\n",
    "\n",
    "algo_model = Model(image_uri=algo_container_uri, \n",
    "                   model_data=algo_model_uri, \n",
    "                   role=iam_role, \n",
    "                   name=algo_model_name, \n",
    "                   sagemaker_session=session, \n",
    "                   env=algo_environment)\n",
    "\n",
    "pipeline_models.append(algo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [<sagemaker.model.Model at 0x7efee22dc110>,\n",
       "  <sagemaker.model.Model at 0x7efee22efb90>],\n",
       " 'role': 'arn:aws:iam::119174016168:role/service-role/AmazonSageMaker-ExecutionRole-20211014T093628',\n",
       " 'predictor_cls': None,\n",
       " 'name': 'DataWranglerInferencePipelineModel-2022-12-23-02-25-44',\n",
       " 'vpc_config': None,\n",
       " 'sagemaker_session': <sagemaker.session.Session at 0x7efee587b510>,\n",
       " 'enable_network_isolation': False,\n",
       " 'endpoint_name': None}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_pipeline_model_name = f\"DataWranglerInferencePipelineModel-{timestamp}\"\n",
    "\n",
    "inference_pipeline_model = PipelineModel(models=pipeline_models, \n",
    "                                         role=iam_role, \n",
    "                                         name=inference_pipeline_model_name, \n",
    "                                         sagemaker_session=session)\n",
    "inference_pipeline_model.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deploy the Pipeline model and create a real-time endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = \"ml.m5.xlarge\"\n",
    "instance_count = 2\n",
    "endpoint_name = f\"DataWranglerInferencePipelineEndpoint-{timestamp}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------!"
     ]
    }
   ],
   "source": [
    "inference_pipeline_model.deploy(instance_count, \n",
    "                                instance_type, \n",
    "                                endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Invoke the Inference Pipeline to get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "predictor = Predictor(endpoint_name, \n",
    "                      sagemaker_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = '2500.0,60.0,15.27,c,car,1.0,30000.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted target is: b'default\\n'\n"
     ]
    }
   ],
   "source": [
    "prediction = predictor.predict(payload, initial_args={\"ContentType\": \"text/csv\"})\n",
    "print(f\"The predicted target is: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted target is: 'fully paid'"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
